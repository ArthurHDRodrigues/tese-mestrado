%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%        Treaps com chave implícita            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Árvore binária de busca com chave implícita}
\label{sec:TreapDeChaveImplicita}

Com uma implementação tradicional de ABB, em que o campo $chave$ dos nós de uma ABB~$T$ com $t$ nós armazena explicitamente os números de $1$ a $t$, é necessário, na operação \treapJoin($T$, $R$), atualizar todas as chaves de~$R$ para que possuam os valores $1+t,2+t, \ldots, r+t$, onde $r$ é o número de nós em~$R$.

Analogamente, com essa implementação tradicional, ao realizar \treapSplit($T$, $\node$) será necessário atualizar todos os nós com chave maior do que a chave de $\node$. No pior dos casos, essas atualizações de chaves podem custar tempo $\O{n}$, onde $n$ é o tamanho das árvores envolvidas.

Para reduzir o número de atualizações desse campo na biblioteca de Euler tour trees, as ABBs utilizadas possuirão \defi{chave implícita}, ou seja, substituímos o campo $chave$ de cada nó pelo campo \defi{tam} que armazena o tamanho da subárvore enraizada naquele nó, isto é, o número de nós nessa subárvore. Assim a chave de cada nó é obtida a partir de sua posição relativa na ABB.

\begin{figure}[htb]
\centering
\input{fig/SEQ-SIZE.tex}
\caption{Árvore da Figura~\ref{fig:seq-treap-indices} exibindo o valor do campo $tam$ abaixo de cada nó.}
\label{fig:seq-treap-size}
\end{figure}

Com essa mudança, não é necessário atualizar as chaves dos nós das árvores em \treapJoin{} e \treapSplit{}, pois as chaves não são mais valores explícitos, mas sim valores relativos, obtidos a partir da posição do nó em sua árvore.  Precisaremos atualizar o campo~$tam$ de alguns nós, mas o custo final do~\treapJoin{} e~\treapSplit{} será ainda assim bem menor.

Como manipularemos muitos ponteiros a ABBs que podem conter $\Nil$, é conveniente a adição da rotina interna \treapGetSize($T$), descrita no Algoritmo~\ref{Algo:treapGetSize}, que retorna $0$ caso $T$ contenha~$\Nil$ e, no caso em que $T$ aponte para uma ABB não vazia, retorna seu tamanho. Essa rotina consome tempos~$\O{1}$.

\begin{algorithm}[!htb]
\caption{\treapGetSize($T$)}
\label{Algo:treapGetSize}
\begin{algorithmic}[1]
\If { $T$ = \Nil}
\State \Return $0$
\EndIf
\State \Return $T$.$tam$
\end{algorithmic}
\end{algorithm}

Com chaves implícitas, a alteração de um nó $x$ torna necessário somente a atualização do campo $tam$ dos nós contidos no caminho entre o nó $x$ e a raiz da ABB que o contém, ou seja, o custo de tempo dessas atualizações será assintoticamente proporcional à altura da ABB. Resta então o desafio de manter a ABB balanceada. Na próxima seção apresentaremos a estrutura de dados treap, que resolve esse desafio sem onerar o custo assintótico das operações ou adicionar demasiada complexidade aos algoritmos.

\section{Treaps}

\defi{Heaps} são árvores binárias quase completas constituídas por nós que possuem quatro campos: prioridade, pai e filhos esquerdo e direito~\cite{CLRS}. Os campos referentes aos pais e filhos dão a estrutura de árvore binária ao heap e a \defi{prioridade} de um nó é um inteiro não negativo. Não apresentaremos a definição de árvore binária quase completa, pois ela é desnecessária para a definição de treaps. Para que uma árvore binária quase completa seja considerada um heap é necessário que a prioridade de cada nó seja maior do que a de seus filhos \TODO{Melhorar essa frase}.

\defi{Treaps} são uma mescla entre árvores binária de busca e heaps. Seus nós possuem cinco campos: $pai$, $esq$, $dir$, $chave$ e $prio$. Os campos $esq$ e $dir$ representam os filhos esquerdo e direito de cada nó, respectivamente, e junto ao campo $pai$ descrevem a estrutura de uma árvore binária. O campo $chave$ satisfaz a propriedade de uma ABB enquanto o campo $prio$ armazena a prioridade do nó e satisfaz a propriedade de um heap. Diferentemente de heaps, treaps não precisam ser quase completas.


Tais árvores foram inicialmente nomeadas \defi{árvores cartesianas} \cite{Vuillemin1980AUL}, pois podemos representar cada nó como um par ordenado em que a primeira coordenada é a chave do nó e a segunda coordenada é sua prioridade. Ao visualizar esses pares imersos no plano cartesiano, como feito na Figura \ref{fig:TREAP}, ambas as estruturas de ABB e heap são bem representadas. Isto é, nós com maior prioridade ficam ilustrados acima de nós com menor prioridade e os nós ficam ordenados de forma crescente, da esquerda para a direita, em função de suas chaves.

\begin{figure}[htb]
\centering
\input{fig/TREAP.tex}
\caption{Uma treap imersa no plano cartesiano.}
\label{fig:TREAP}
\end{figure}

\section{Implementação de árvore binária de busca de chave implícita com treaps}
\label{sec:imple-treap}
A implementação das rotinas \treapGetRoot{}, \treapSearch{}, \treapOrder{} e~\treapGetLast{} independem da técnica que usaremos para balancear a treap, pois são consultas e somente usam a estrutura da ABB de chave implícita, assim já podem ser apresentadas nos Algoritmos~\ref{Algo:treapGetRoot},~\ref{Algo:TREAPsearch},~\ref{Algo:treapGetLast} e~\ref{Algo:TREAPorder}.

\begin{algorithm}[htb]
\caption{\treapGetRoot($\node$)}
\label{Algo:treapGetRoot}
\begin{algorithmic}[1]
\State $raiz$ $\gets$ $\node$
\While {$raiz$.$pai$ $\neq \Nil$}
\State  $raiz$ $\gets$  $raiz$.$pai$
\EndWhile
\State \Return $raiz$
\end{algorithmic}
\end{algorithm}

O consumo de tempo das rotinas \treapGetRoot{}, \treapSearch{}, \treapGetLast{} e \treapOrder{} é~$\O{h}$ onde~$h$ é a altura da árvore. Para balancear uma treap e assim garantir consumo de tempo logarítmico, Seidel e Aragon~\cite{AragonSeidel1996} propuseram escolher a prioridade de cada nó de forma aleatória com distribuição de probabilidade uniforme em um universo suficientemente grande para que a probabilidade de haver nós com a mesma prioridade seja próxima de $0$. Como exemplo, os autores sugerem usar como universo os inteiros entre $0$ e~$2^{31}$.

\begin{algorithm}
\caption{\treapSearch($T$, $k$)}
\label{Algo:TREAPsearch}
\begin{algorithmic}[1]
\If { $T$.$esq$.$tam$ $\geqslant$ $k$}
\State \Return \treapSearch($T$.$esq$, $k$)
\EndIf
\If { $T$.$esq$.$tam$+1 = $k$}
\State \Return $T$
\EndIf
\State \Return \treapSearch($T.dir$, $k$-\treapGetSize($T$.$esq$)-1)
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{\treapGetLast($T$)}
\label{Algo:treapGetLast}
\begin{algorithmic}[1]
\State \Return \treapSearch($T$, \treapGetSize($T$))
\end{algorithmic}
\end{algorithm}

Para representar essa escolha aleatória, usaremos uma função auxiliar \random($r$) que retorna um inteiro positivo menor do que $r$ com probabilidade uniforme. Esse tipo de função está presente nativamente em diversas linguagens de programação \TODO{(}e a elaboração de sua implementação foge do escopo desse texto \TODO{). Removo a parte entre parênteses?}. Consideraremos que seu consumo de tempo é~$\O{1}$.

\begin{algorithm}
\caption{\treapOrder($u$)}
\label{Algo:TREAPorder}
\begin{algorithmic}[1]
\State $ordem$ $\gets$ 1 + \treapGetSize($u$.$esq$)
\While { $u$.$pai$ $\neq$ \Nil{}}
\If { $u = u$.$pai$.$dir$}
  \State $ordem$ $\gets$ $ordem$ + 1 + \treapGetSize($u$.$pai$.$esq$)
\EndIf
  \State $u$ $\gets$ $u$.$pai$
\EndWhile
\State \Return $ordem$
\end{algorithmic}
\end{algorithm}

Com essa técnica de balanceamento de treaps em mãos, podemos apresentar a implementação dos demais algoritmos que compõem essa biblioteca.

\begin{algorithm}
\caption{\treapCreate($v$)}
\label{Algo:TREAPbuild}
\begin{algorithmic}[1]
\State \malloc(\sizeof($\node$))\Comment{aloca espaço para um novo nó}
\State $\node$.$tam$ $\gets 1$
\State $\node$.$prio$ $\gets$ \random($2^{31}$)
\State $\node$.$info$ $\gets$ $v$
\State $\node$.$esq$ $\gets$ $\node$.$dir$ $\gets$ $\node$.$pai$ $\gets$ \Nil
\State \Return $\node$
\end{algorithmic}
\end{algorithm}

\newpage
A rotina \treapCreate{} consome~$\O{1}$ enquanto que \treapJoin{} consome $\O{h}$ onde~$h$ é a soma das alturas das duas árvores que são unidas e \treapSplit{} consome $\O{h}$ onde~$h$ é a altura da árvore original. Como a altura esperada dessas árvores é  $\O{\lg n}$, teremos que o consumo de tempo dessas duas rotinas também será logarítmico.

\begin{algorithm}
\caption{\treapJoin($T$, $R$)}
\label{Algo:TREAPjoin}
\begin{algorithmic}[1]
\If { $T$ = \Nil} \Return $R$
\EndIf
\If { $R$ = \Nil} \Return $T$
\EndIf

\If { $T$.$prio$ $>$ $R$.$prio$}
  \State $T$.$dir$ $\gets$ \treapJoin($T$.$dir$, $R$)
  \State $T$.$dir$.$pai$ $\gets$ $T$
  \State $T$.$tam$ $\gets$ \treapGetSize($T$.$dir$)+\treapGetSize($T$.$esq$)+$1$
  \State \Return $T$
\Else 
  \State $R$.$esq$ $\gets$ \treapJoin($T$, $R$.$esq$)
  \State $R$.$esq$.$pai$ $\gets$ $R$
  \State $R$.$tam$ $\gets$ \treapGetSize($R$.$dir$)+\treapGetSize($R$.$esq$)+$1$
  \State \Return $R$
\EndIf
\end{algorithmic}
\end{algorithm}
\begin{algorithm}
\caption{\treapSplit($u$)}
\label{Algo:TREAPsplit}
\begin{algorithmic}[1]
\If { $u$ $=$ \Nil} \Return \Nil, \Nil
\EndIf
\State $R$ $\gets $ $u$
\State $L$ $\gets $ $u$.$esq$
\State $u$.$esq$ $\gets\Nil$
\If { $L$ $\neq$ \Nil} $L$.$tam$ $\gets$ \treapGetSize($L$.$dir$)+\treapGetSize($L$.$esq$)+$1$
\EndIf
\State $tmp$ $\gets$ $u$
\While { $tmp$.$pai$ $\neq \Nil$}
  \If { $tmp$.$pai$.$dir$ = $tmp$}
    \State $tmp$.$pai$.$dir$ $\gets$ $L$ \Comment se for filho à direita, então deve ficar em $L$
    \If { $L$ $\neq$ \Nil} $L$.$pai$ $\gets$ $tmp$.$pai$
    \EndIf
    \State $L$ $\gets$ $tmp$.$pai$

    \State $L$.$tam$ $\gets$ \treapGetSize($L$.$dir$)+\treapGetSize($L$.$esq$)+$1$
  \Else
    \State $tmp$.$pai$.$esq$ $\gets$ $R$
    \If { $R \neq \Nil$} $R$.$pai$ $\gets$ $tmp$.$pai$
    \EndIf
    \State $R$ $\gets$ $tmp$.$pai$
    \State $R$.$tam$ $\gets$ \treapGetSize($R$.$dir$)+\treapGetSize($R$.$esq$)+$1$
  \EndIf
  \State $tmp$ $\gets$ $tmp$.$pai$
\EndWhile
\If { $L$ $\neq \Nil$} $L$.$pai$ $\gets\Nil$\EndIf
\If { $R$ $\neq \Nil$} $R$.$pai$ $\gets\Nil$\EndIf
\State\Return $L$, $R$
\end{algorithmic}
\end{algorithm}



\newpage
\chapter{Conexidade em grafos dinâmicos}
\label{sec:connDG}
Retomemos o problema de conexidade em grafos dinâmicos inicialmente apresentado na Seção~\ref{sec:Motivação} e que é um dos problemas principais que vamos estudar. Ele consiste na busca por uma implementação tão eficiente quanto possível para a seguinte biblioteca: 
\begin{itemize}
\item \dymGraphCreate($n$): cria um grafo dinâmico com $n$ vértices isolados;
\item \dymGraphAddEdge($G$, $u$, $v$): adiciona a aresta $uv$ ao grafo dinâmico $G$;
\item \dymGraphDelEdge($G$, $u$, $v$): remove a aresta $uv$ de $G$; e
\item \dymGraphQuery($G$, $u$, $v$): retorna verdadeiro se $u$ e $v$ estão na mesma componente conexa de $G$ e falso, caso contrário.
\end{itemize}

Note que dois vértices estão na mesma componente conexa de~$G$ se e somente se estão na mesma componente de alguma floresta maximal de~$G$, pois, por definição, por ser maximal, não é possível haver um caminho entre dois vértices em~$G$ de forma que não haja um caminho entre esses mesmo dois vértices na floresta maximal. Dessa forma, a ideia que usaremos para responder a consulta de conexidade em nosso grafo dinâmico é manter, ao longo da sequência de inserções e remoções de arestas, uma floresta dinâmica~$F$ que seja maximal em~$G$ e quando ocorrer a consulta \dymGraphQuery{}, chamamos a consulta de conexidade na floresta~$F$.

A rotina \dymGraphCreate{} retorna um grafo composto por $n$ vértices isolados. Esse grafo já é uma floresta maximal.

Em uma chamada~\dymGraphAddEdge($G$, $u$, $v$), primeiro testamos a conexidade de $u$ com $v$. Se esses vértices não estiverem conectados em~$G$, então inserimos a aresta $uv$ na floresta maximal que estamos mantendo, assim ligando as duas árvores que contém~$u$ e~$v$ nessa floresta. Essas arestas serão chamadas de \defi{arestas da floresta} ou \defi{arestas titulares}.

Já no caso em que $u$ e $v$ estiverem conectados em~$G$, então a aresta sobressalente~$uv$ será chamada de \defi{aresta reserva} e iremos armazená-la em uma estrutura de dados auxiliar~$R$ dada por listas de adjacências. Para manusear~$R$, usamos a seguinte biblioteca:
\begin{itemize}
    \item \graphCreate($n$): cria e devolve um grafo mantido com listas de adjacências com $n$ vértices isolados.
    \item \graphAdd($G$, $u$, $v$): adiciona $u$ na lista de adjacências de $v$ em $G$ e vice-versa.
    \item \graphDel($G$, $u$, $v$): remove $u$ da lista de adjacências de $v$ em $G$ e vice-versa.
\end{itemize}

 Vimos, na Seção~\ref{sec:connDF}, que a inserção de arestas em uma floresta dinâmica custa tempo~$\O{\lg n}$. Para implementar as listas de adjacências, usaremos tabelas de símbolos que permitem inserção em tempo esperado~$\O{1}$. Assim o custo de~\dymGraphAddEdge{} é~$\O{\lg n}$.

Para remover uma aresta reserva, basta remove-la das listas de adjacências, que também será feito em tempo esperado~$\O{1}$. Já remover uma aresta~$uv$ da floresta é demasiadamente mais complexo, pois sua remoção gera duas árvores~$T_u$ e~$T_v$, que contêm os vértices~$u$ e~$v$, respectivamente. Esse cenário pode ser visto na Figura~\ref{fig:DG-exemploTu-Tv}. Para manter a propriedade de~$F$ ser maximal em~$G$, é necessário verificar se existe alguma aresta reserva em~$R$ que liga~$T_u$ a~$T_v$. Tal aresta é chamada de \defi{aresta substituta}.

Sem perda de generalidade, podemos supor que $|T_u|\leqslant |T_v|$. Então, para encontrar uma aresta substituta se tal aresta exista, podemos percorrer cada vértice $t$ de $T_u$ verificando se existe algum vértice $w$ na lista de adjacências de $t$ que não seja vértice de $T_u$. Caso $w$ não seja vértice de $T_u$, como $F$ era maximal, teremos que $w$ necessariamente é um vértice de $T_v$, assim a aresta $tw$ é uma substituta para a aresta $uv$ que foi removida.

\begin{figure}[htb]
%\scalebox{.6}{
\centering
\input{fig/DG-exemploTu-Tv}%}
\caption{Exemplo de grafo dinâmico com as arestas da árvore~$T$ coloridas de vermelho, enquanto que as arestas reservas estão pintadas de preto. A aresta~$uv$ removida está pontilhada.}
\label{fig:DG-exemploTu-Tv}
\end{figure}

Para testar rapidamente se~$t$ e~$w$ estão na mesma árvore em~$F$ depois da remoção de~$uv$, basta acionar a rotina \dymForestQuery($F$, $t$, $w$), que vimos que consome tempo esperado~$\O{\lg n}$. A rotina~\dymForestQuery{}, no pior dos casos, em que não há aresta substituta, será chamada~$\Theta(n^2)$ vezes, o que implica em um consumo esperado de tempo de~$\O{n^2\lg n}$ para o algoritmo implementado dessa forma.

Notemos que somente a remoção de arestas de~$F$ é lenta, isso se deve à necessidade de busca por uma aresta substituta. Para obter uma implementação melhor, é necessário reduzir o número de arestas testadas para encontrar uma substituta. A técnica que apresentaremos no restante dessa seção, deve-se a Jacob Holm, Kristian De Lichtenberg e Mikkel Thorup~\cite{poly_log} e tem como objetivo a redução deste número de forma amortizada. Após uma rápida introdução de notação, poderemos implementar \dymGraphCreate{}, \dymGraphAddEdge{} e~\dymGraphQuery{} como descrito anteriormente, sendo necessários mais artifícios para obtermos uma implementação eficiente de~\dymGraphDelEdge{}.


\section{Fatiamento do grafo em níveis}
Cada aresta do grafo possuirá um \defi{nível} entre $1$ e $\lceil \lg n \rceil$, onde $n$ é o número de vértices do grafo. O valor inicial do nível de uma aresta recém inserida é $\lceil \lg n \rceil$ e é decrementado toda vez que percorremos a aresta em busca de uma aresta substituta. O nível de uma aresta nunca aumentá, somente diminuirá. 

Dado um grafo $G$, podemos definir o grafo~$G_{\leqslant i}$ como o grafo induzido pelas arestas de nível menor ou igual a~$i$. Para cada nível $i$, manteremos uma floresta maximal~$F_{\leqslant i}$ de~$G_{\leqslant i}$ e o grafo~$R_i$, guardado com listas de adjacências, dado pelas arestas reservas de nível~$i$. Trivialmente temos que $G = G_{\leqslant \lceil \lg n \rceil}$ e portanto $F_{\leqslant \lceil \lg n \rceil}$ é uma floresta maximal de~$G$. Ao longo da sequência de modificações realizadas no grafo, manteremos algumas invariantes importantes:
\begin{enumerate}[label=(\roman*)]
    \item $F_{\leqslant i}$ é uma floresta maximal de~$G_{\leqslant i}$ para todo $1\leqslant i \leqslant \lceil \lg n \rceil$; e\label{invar:SF}
    \item $F_{\leqslant i}\subseteq F_{\leqslant i+1}$, para todo $1\leqslant i \leqslant \lceil \lg n \rceil-1$; \label{invar:contida}
    \item Cada componente de $F_{\leqslant i}$ possui no máximo $2^i$ vértices.\label{invar:tamanho}
\end{enumerate}

Para cada rotina da biblioteca de grafos dinâmicos, vamos primeiramente descrever o que a rotina faz, em seguida vamos mostrar que tal rotina preserva as invariantes acima e por fim calcular seu consumo de tempo.

\section{Implementação}
\subsection{Criação de um grafo dinâmico}

A implementação de \dymGraphCreate{} pode ser vista no Algoritmo~\ref{Algo:dymGraphCreate}. Nessa implementação, simplesmente inicializamos cada $F_{\leqslant i}$ e~$R_i$ de~$G$ usando \dymForestCreate{} e~\graphCreate{}, respectivamente. Notemos que essas rotinas retornam a floresta e o grafo dados por~$n$ vértices isolados, dessa forma~$F_{\leqslant \lceil \lg n \rceil}$ e~$R_{\lceil \lg n \rceil}$ juntos representam um grafo dinâmico vazio, que é exatamente o grafo que queremos construir com \dymGraphCreate{}. Além disso, será útil obter o nível de uma aresta $uv$ em tempo esperado constante, assim manteremos um dicionário $G$.\nivel{} que relaciona cada aresta a seu nível. Para manusear esse dicionário, usaremos uma biblioteca análoga à usada na Seção~\ref{sec:impleDF-ETT}, que \NEW{relembramos a seguir. Quando for claro, referenciaremos esse dicionario no pseudo-código somente por \nivel:
\begin{itemize}
    \item $\nivel~\gets~\hashCreate(n^2)$: cria e retorna um dicionário~\nivel{} capaz de armazenar $n^2$ valores;
    \item $\nivel[u,v]~\gets~i$: associa o nível~$i$ à aresta $uv$. Se já houver um nível associado a~$uv$, então esse valor é substituído por~$i$;
    \item $var~\gets~\nivel[u,v]$: atribui o nível da aresta $uv$ à variável $var$.
\end{itemize}}

\begin{algorithm}
\caption{\dymGraphCreate($n$)}
\label{Algo:dymGraphCreate}
\begin{algorithmic}[1]
\For { $i$ $\gets$ 1 até $\lceil \lg n \rceil$}
\State $G.F_{\leqslant i} \gets$ \dymForestCreate($n$)
\State $G.R_i \gets$ \graphCreate($n$)
\EndFor
\State $G$.\nivel{} $\gets$ \hashCreate($n^2$)
\State \Return $G$ 
\end{algorithmic}
\end{algorithm}


Notemos que as invariantes são mantidas por~\dymGraphCreate{}, pois o grafo gerado por essa rotina são~$n$ vértices isolados. Assumindo que o consumo de tempo de~\graphCreate{} seja~$\O{n}$, então o consumo de tempo dessa rotina será $\O{n\lg n}$.

\subsection{Consulta de conexidade}

Para realizar a rotina \dymGraphQuery{}, apresentada no Algoritmo~\ref{Algo:dymGraphQuery}, somente retornamos a resposta da consulta de conexidade feita em~$F_{\lceil \lg n \rceil}$. A corretude desse algoritmo se deve ao invariante~\ref{invar:SF}, pois esse invariante garante que~$F_{\lceil \lg n \rceil}$ é uma floresta maximal de~$G$, logo consultas de conectividade entre os vértices~$u$ e~$v$ em~$G$ e em~$F_{\lceil \lg n \rceil}$ devem possuir a mesma resposta.

\begin{algorithm}
\caption{\dymGraphQuery($G$, $u$, $v$)}
\label{Algo:dymGraphQuery}
\begin{algorithmic}[1]
\State \Return \dymForestQuery($G$.$F_{\leqslant\lceil \lg n \rceil}$, $u$, $v$)
\end{algorithmic}
\end{algorithm}

A rotina \dymGraphQuery{} claramente não interfere nas invariantes, já que  é somente uma consulta que não modifica as estruturas de dados do grafo.

Como o consumo esperado de \dymForestQuery{} é~$\O{\lg n}$, é imediato ver que o consumo de tempo esperado de \dymGraphQuery{} também é~$\O{\lg n}$.

\subsection{Adição de arestas}

Para inserir uma nova aresta~$uv$ em~$G$ usando a rotina \dymGraphAddEdge{}, implementada no Algoritmo~\ref{Algo:dymGraphAddEdge}, primeiro verificamos se os vértices~$u$ e~$v$ estão conectados em~$G$ usando a rotina \dymForestQuery($G.F_{\leqslant \lceil \lg n \rceil}$, $u$, $v$). Como já comentamos, garantimos que esse teste funciona graças ao invariante~\ref{invar:SF}. Caso~$u$ e~$v$ estiverem conectados em~$G$, então a aresta $uv$ é uma aresta reserva e será inserida em $R_{\lceil \lg n \rceil}$. Caso~$u$ e~$v$ não estiverem conectados, então a aresta $uv$ deve ser inserida em~$F_{\leqslant \lceil \lg n \rceil}$.

\begin{algorithm}
\caption{\dymGraphAddEdge($G$, $u$, $v$)}
\label{Algo:dymGraphAddEdge}
\begin{algorithmic}[1]
\State \nivel[$u$,$v$] $\gets$ $\lceil \lg n \rceil$
\If {\dymForestQuery($G.F_{\leqslant\lceil \lg n \rceil}$, $u$, $v$)}
\State \graphAdd($G$.$R_{\lceil \lg n \rceil}$, $u$, $v$)
\Else 
\State \dymForestAddEdge($G.F_{\leqslant\lceil \lg n \rceil}$, $u$, $v$)
\EndIf
\end{algorithmic}
\end{algorithm}

Note que a invariante~\ref{invar:SF} é mantida para $i = \lceil \lg n \rceil$ e as demais invariantes também se mantêm, pois somente o nível $\lceil \lg n \rceil$ da nossa estrutura de dados foi modificado, já que a nova aresta é inserida no nível~$\lceil \lg n \rceil$. 

O custo esperado de tempo de \dymForestQuery{} e \dymGraphAddEdge{} são~$\O{\lg n}$ e o custo esperado de \graphAdd{} é~$\O{1}$. Logo o custo esperado de \dymGraphAddEdge{} também é~$\O{\lg n}$.

\subsection{Remoção de arestas}

\newcommand{\ceil}[1]{\lceil{#1}\rceil}

A complexidade da remoção de uma aresta em um grafo dinâmico vem da busca por uma aresta substituta para a aresta removida. Podemos encapsular essa busca em uma rotina própria chamada \defi{\dymGraphReplace{}}. A rotina \dymGraphReplace{} recebe um grafo dinâmico~$G$, um inteiro $i$ com $1 \leq i \leq \ceil{\lg n}$, e dois vértices $u$ e $v$, extremidades de uma aresta de nível $i$ que acabou de ser removida de $G$ e das florestas~$F_{\leqslant j}$ para~$j \geq i$, e encontra, caso exista, uma aresta substituta em~$G$ com nível mínimo, e a insere na floresta deste nível e nas de nível acima. Dessa forma, a implementação de \dymGraphDelEdge{}, descrita no Algoritmo~\ref{Algo:dymGraphDelEdge}, pode ser feita em poucas linhas.

\begin{algorithm}
\caption{\dymGraphDelEdge($G$, $u$, $v$)}
\label{Algo:dymGraphDelEdge}
\begin{algorithmic}[1]
\State $i$ $\gets$ \nivel[$u,v$]
\If {$uv$ $\in G.F_{\leqslant\lceil \lg n \rceil}$}\label{Algo:dymGraphDelEdge:linha:if}
\For {$j$ $\gets$ $i$ até $\lceil \lg n \rceil$}\label{linha2}
\State \dymForestDelEdge($G$.$F_j$, $u$, $v$))
\EndFor
\State \dymGraphReplace($G$, $u$, $v$, $i$)
\Else
  \State \graphDel($G$.$R_i$, $u$, $v$)\label{Algo:dymGraphDelEdge:linha:removeLA}
\EndIf
\end{algorithmic}
\end{algorithm}

Para remover uma aresta~$uv$ de nível~$i$ de~$G$, primeiro precisamos determinar se ela pertence à floresta $F_{\leqslant\lceil \lg n \rceil}$ ou não, o que é feito na linha~\ref{Algo:dymGraphDelEdge:linha:if}. Para tal, o teste da linha~\ref{Algo:dymGraphDelEdge:linha:if} consulta se a tabela de símbolos $F_{\leqslant\lceil \lg n \rceil}$.\dymForestHash{} possui alguma entrada associada à chave~$(u,v)$. Caso a aresta $uv$ não seja titular, 
ela é uma aresta de~$R_i$ e somente a removemos de~$R_i$, o que é feito na linha~\ref{Algo:dymGraphDelEdge:linha:removeLA}.
Caso $uv$ seja titular, então precisamos removê-la de todos os níveis em que ela está presente.  Devido ao invariante~\ref{invar:contida}, sabemos que $uv$ está nos níveis de $i$ até~$\lceil \lg n \rceil$, então essa remoção é feita no laço da linha~\ref{linha2}.  
A rotina \dymGraphReplace{} faz as alterações devidas à busca de uma aresta substituta, e sua eventual inclusão nas florestas apropriadas de forma a manter os invariantes.
Veremos que o \dymGraphReplace{} garante que cada $F_{\leqslant i}$ é maximal em~$G_{\leqslant i}$, isto é, preserva a invariante~\ref{invar:SF} e preserva também as invariantes~\ref{invar:contida} e~\ref{invar:tamanho}.

O laço da linha~\ref{linha2} terá custo esperado~$\O{\lg^2 n}$, pois executa no pior dos casos $\lceil \lg n \rceil$ vezes a rotina \dymForestDelEdge{}, que possui custo esperado~$\O{\lg n}$. Veremos que \dymGraphReplace{}, descrito no Algoritmo~\ref{Algo:dymGraphReplace}, possui custo amortizado~$\O{\lg n^2}$. Assim concluímos que o custo de tempo esperado amortizado de \dymGraphDelEdge{} será~$\O{\lg^2 n}$.

\medskip

Para entender melhor o funcionamento do algoritmo~\dymGraphReplace{}, descrito no Algoritmo~\ref{Algo:dymGraphReplace}, vamos retomar o processo de busca de uma aresta substituta que foi comentado no início dessa seção, mas agora agregando a estrutura de níveis e as invariantes que definimos. Para tal, ilustramos, na Figura~\ref{fig:DG-antes-de-rebaixar}, o grafo da Figura~\ref{fig:DG-exemploTu-Tv} com a estrutura de níveis e com a aresta $uv$ já removida. Consideramos que todas as arestas desse grafo são de nível $i$ e também que não há aresta de nível~$i-1$ imediatamente antes da chamada de \dymGraphReplace{}.
\begin{figure}[htb]
%\scalebox{.6}{
\centering
\input{fig/DG-antes-de-rebaixar}%}
\caption{Grafo da Figura~\ref{fig:DG-exemploTu-Tv} imerso no nível~$i$ com aresta $uv$ removida.}
\label{fig:DG-antes-de-rebaixar}
\end{figure}

\begin{algorithm}
\caption{\dymGraphReplace($G$, $u$, $v$, $niv$)}
\label{Algo:dymGraphReplace}
\begin{algorithmic}[1]
\For {$i$ $\gets$ $niv$ até $\lceil \lg n \rceil$}\label{Algo:dymGraphReplace:linha:primeira}
\State $T_v$ $\gets$  \treapGetRoot($F_i[v,v]$)
\State $T_u$ $\gets$  \treapGetRoot($F_i[u,u]$)
\If {$\treapGetSize(T_v) < \treapGetSize(T_u)$}\Comment{Garantimos que $|T_v|\geqslant |T_u|$}
\State $u$ $\leftrightarrow$ $v$
\State $T_u \leftrightarrow T_v$
\EndIf
\For {$xy$ em $T_u$ com nível = $i$}\label{Algo:dymGraphReplace:linha:moveTu}\Comment{Move $T_u$ para o nível $i-1$}
\State \nivel$[x,y]$ $\gets$ $i-1$
\State \dymForestAddEdge($G$.$F_{i-1}$, $x$, $y$) 
\EndFor
\For {$xy$ em $G$.$R_i$ com $x$ em $T_u$}\label{Algo:dymGraphReplace:linha:achaSub}\Comment{Procura substituta para $uv$}
\State \graphDel($G$.$R_i$, $x$, $y$)
\If {$y \in T_v$}
\For {$j \gets i$ até $\lceil \lg n \rceil$}\label{Algo:dymGraphReplace:linha:inseresub}
\State \dymForestAddEdge($G$.$F_j$, $x$, $y$)
\EndFor
\State \Return
\Else
\State \nivel$[x,y]$ $\gets$ $i-1$
\State \graphAdd($G$.$R_{i-1}$, $x$, $y$)
\EndIf
\EndFor
\EndFor\label{Algo:dymGraphReplace:linha:ultima}
\end{algorithmic}
\end{algorithm}


No que segue, $|T|$ denota o número de vértices numa árvore~$T$.
Após a remoção de uma aresta $uv$ de nível $i$ de uma componente $T$ da floresta $F_{\leqslant i}$, a árvore $T$ é dividida em duas árvores, $T_u$ e $T_v$, que contém $u$ e $v$, respectivamente. Podemos supor que~$|T_u|\leqslant |T_v|$. Pela invariante~\ref{invar:tamanho}, vale que $|T| \leq 2^i$ e, como ${|T_u| + |T_v| = |T|}$, concluímos que $|T_u| \leq 2^{i-1}$. Logo podemos mover todas as arestas de nível~$i$ de~$T_u$ para o nível $i-1$ sem infringir o invariante~\ref{invar:tamanho} para $i-1$.  Esse rebaixamento é feito no laço da linha~\ref{Algo:dymGraphReplace:linha:moveTu} e ilustramos a estrutura resultante dele na Figura~\ref{fig:DG-depois-de-rebaixar}.

\begin{figure}[htb]
%\scalebox{.6}{
\centering
\input{fig/DG-depois-de-rebaixar}%}
\caption{Grafo dinâmico após o rebaixamento de $T_u$.}
\label{fig:DG-depois-de-rebaixar}
\end{figure}

Agora percorreremos as arestas reservas em busca de uma substituta. Notemos que, como consequência das invariantes~\ref{invar:SF} e~\ref{invar:contida}, temos que se há uma aresta substituta para~$uv$, então seu nível é maior ou igual a~$i$. Provaremos esse fato por contradição, supondo que exista uma aresta~$xy$ substituta a~$uv$ com nível $j<i$ e, sem perda de generalidade, supondo que~$x$ é um vértice de~$T_u$ e~$y$ de~$T_v$. É imediato notar que $xy$ é uma aresta de $G_{\leqslant j}$, mas que não é uma aresta de~$F_{\leqslant j}$, pois, sendo uma aresta reserva, $xy\notin F_{\leqslant \lceil \lg n \rceil}$ e como~$F_{\leqslant j} \subseteq F_{\leqslant \lceil \lg n \rceil}$  pela invariante~\ref{invar:contida}, temos que~$xy\notin F_{\leqslant j}$. Como $xy$ é uma aresta de $G_{\leqslant j}$, temos que $x$ e $y$ estão na mesma componente de $G_{\leqslant j}$, e portanto deveriam estar na mesma componente de $F_{\leqslant j}$ pela invariante~\ref{invar:SF}. Mas isso contraria a invariante~\ref{invar:contida}, dado que $x$ e $y$ estão em componentes distintas, $T_u$ e $T_v$, de $F_{\leqslant i}$.

Percorremos as arestas reservas de nível~$i$ incidentes a~$T_u$ procurando uma aresta substituta. Essas arestas estão pintadas de preto na Figura~\ref{fig:DG-depois-de-rebaixar}. Cada aresta percorrida desta forma e que não seja uma substituta de~$uv$ tem seus dois extremos em $T_u$ e também será rebaixada.
Rebaixamos tais arestas de nível, pois elas deixam de ser candidatas a substitutas de arestas de nível~$i$, uma vez que rebaixamos as arestas de~$T_u$ de nível $i$ para nível $i-1$. 
Ademais esse rebaixamento não infringe o invariante~\ref{invar:SF}.
Caso encontremos uma substituta no nível~$i$, então a inserimos nas florestas dos níveis~$i$ até~$\lceil \lg n \rceil$. Caso não encontremos uma substituta no nível~$i$, teremos rebaixado para o nível $i-1$ todas as arestas incidentes a $T_u$, e repetimos a busca no nível~$i+1$, eventualmente rebaixando arestas de nível $i+1$ para o nível $i$, até encontrarmos uma aresta substituta ou terminarmos a busca no nível~$\lceil \lg n \rceil$. Podemos ver o resultado desses rebaixamentos na Figura~\ref{fig:DG-depois-achou-sub}.
\begin{figure}[htb]
%\scalebox{.6}{
\centering
\input{fig/DG-depois-achou-sub}%}
\caption{Grafo dinâmico após encontrar uma aresta substituta para $uv$.}
\label{fig:DG-depois-achou-sub}
\end{figure}

A rotina \dymGraphReplace{} preserva cada uma das invariantes que definimos. 
Como somente rebaixamos arestas da árvore e arestas reservas cujas duas extremidades estão em~$T_u$, a componente resultante de $F_{\leqslant i-1}$ é maximal em~$G_{\leqslant i-1}$. Portanto a invariante~\ref{invar:SF} é preservada.
A invariante~\ref{invar:contida} é preservada, pois rebaixar arestas de nível mantém essa invariante e ao inserir uma aresta que foi descoberta como substituta, garantimos que ela foi inserida em todos os níveis maiores do que~$i$ (laço da linha~\ref{Algo:dymGraphReplace:linha:inseresub}).  
Como garantimos que $|T_u| \leqslant 2^{i-1}$ antes de rebaixar as arestas de $T_u$, a invariante~\ref{invar:tamanho} também é preservada.

Antes de analisar o consumo de tempo de \dymGraphReplace{}, é necessário elaborar mais alguns detalhes sobre a implementação dessa rotina. Especificamente, vamos detalhar como realizamos os laços das linhas~\ref{Algo:dymGraphReplace:linha:moveTu} e~\ref{Algo:dymGraphReplace:linha:achaSub}.

No laço da linha~\ref{Algo:dymGraphReplace:linha:moveTu}, percorremos o conjunto das arestas de nível~$i$ de~$T_u$. Para acessar esse conjunto eficientemente, adicionaremos dois novos campos aos nós da Euler Tour Tree que armazena~$T_u$. O primeiro será um campo booleano, chamado~$niv$, que valerá~$1$ somente se a aresta representada pelo nó for de nível~$i$. Caso contrário, esse campo valerá $0$. O segundo campo, chamado~$cniv$, armazena o número de arestas de nível $i$ na subárvore enraizada pelo nó. Podemos ver na Figura~\ref{fig:DG-TREAP-niv}, como exemplo, a floresta $F_{\leqslant i}$ da Figura~\ref{fig:DG-depois-achou-sub} representada por uma Euler tour tree.

\begin{figure}[htb]
\scalebox{.61}{
\centering
\input{fig/DG-TREAP-niv}}
\caption{Euler tour tree que armazena a floresta $F_{\leqslant i}$ da Figura~\ref{fig:DG-depois-achou-sub}. Os nós que representam arestas de nível~$i$ de $F_{\leqslant i}$ estão pintados de vermelho e o valor do campo $cniv$ está denotado abaixo de cada nó, quando esse campo não for nulo.}
\label{fig:DG-TREAP-niv}
\end{figure}

Com esses dois campos, podemos adicionar uma nova rotina, chamada \treapGetEdgesLevel{} e descrita no Algoritmo~\ref{Algo:treapGetEdgesLevel}, que percorre a Euler Tour Tree que armazena~$T_u$ evitando subárvores que não possuam arestas de nível~$i$ e constrói o conjunto de todas as arestas de nível~$i$ de~$T_u$.

\begin{algorithm}
\caption{\treapGetEdgesLevel($\node$, $k$)}
\label{Algo:treapGetEdgesLevel}
\begin{algorithmic}[1]
\If {$\node$ $=$ \Nil{} ou $\node$.$cniv$ $=0$}
\State \Return \Nil
\EndIf
\If {$\node.esq$ $\neq$ \Nil{} e $\node.esq$.$cniv$ $\geqslant k$}
\State  \Return \treapGetEdgesLevel($\node.esq$, $k$)
\EndIf
\If {$\node.esq$ $\neq$ \Nil{} e $\node.esq$.$cniv +1$ $=k$ e $\node.niv$}
\State  \Return $\node$
\EndIf
\State \Return \treapGetEdgesLevel($\node.dir$, $k-\node.esq$.$cniv-\node.niv$)

\end{algorithmic}
\end{algorithm}

Notemos que \treapGetEdgesLevel{} não altera as estruturas de dados, logo preserva as invariantes. Seu consumo de tempo esperado é $\O{k \lg n}$, onde $k$ é o número de arestas de nível~$i$ na árvore de $F_{\leqslant i}$ que contém o $\node$, que corresponde aos $k$ percursos da raiz da Euler Tour Tree até cada nó com campo $niv$ sendo igual a~$1$, como a Euler Tour Tree é balanceada, cada percurso possui custo de percurso~$\O{\lg n}$.

Com essa nova rotina em mãos, realizar o laço da linha~\ref{Algo:dymGraphReplace:linha:moveTu} se torna fácil, primeiro construímos esse conjunto de arestas titulares de nível~$i$ e então a percorremos, rebaixando cada aresta para o nível~$i-1$.

A técnica utilizada para o laço~\ref{Algo:dymGraphReplace:linha:achaSub} é completamente análoga. Só que agora a informação que queremos extrair da Euler Tour Tree é o conjunto de vértices incidentes à alguma aresta reserva de nível~$i$. Logo, adicionaremos dois outros novos campos aos nós das nossas Euler Tour Trees. O primeiro, chamado $res$, que é igual a~$1$ se o nó é a ocorrência ativa de um vértice $v$, isto é, contém a ocorrência~$vv$ apontada pela tabela de símbolos da floresta e $v$ é incidente alguma aresta reserva de nível~$i$, caso contrário, valerá~$0$. O segundo será um contador, chamado de~$cres$, que armazena o número de nós que satisfazem $res$ $=$ $1$ na subárvore enraizada pelo nó. Podemos ver, na Figura~\ref{fig:DG-TREAP-res}, o valor desses campos para o grafo dinâmico de nível~$i$ da Figura~\ref{fig:DG-depois-achou-sub}. A manutenção desses campos é análoga à manutenção feita nos campos $niv$ e~$cniv$.

\begin{figure}[htb]
\scalebox{.61}{
\centering
\input{fig/DG-TREAP-res}}
\caption{Euler tour tree que armazena o grafo de nível~$i$ da Figura~\ref{fig:DG-depois-achou-sub}. Os nós que representam vértices incidentes a arestas reservas de nível~$i$ estão pintados de azul e o valor do campo~$cres$ está denotado abaixo de cada nó, quando esse campo não for nulo.}
\label{fig:DG-TREAP-res}
\end{figure}

Podemos fazer a manutenção desses novos campos sem onerar o custo das outras rotinas. Toda nova aresta inserida em algum nível possui o campo $niv$ igual a $1$, esse campo se torna $0$ somente quando rebaixamos essa aresta de nível. Toda manutenção que o campo $cniv$ pede é a sua atualização toda vez que atualizamos o campo $.tam$ das treaps. Isso se deve ao fato de atualizarmos $.tam$ quando a estrutura das subárvores de um nó terem suas estruturas modificadas, nesse caso, essa modificação de estrutura infere também na necessidade de atualização dos demais contadores. O segundo contador, $cres$, exige atualizações em situações adicionais. Toda vez que adicionamos ou removemos uma aresta reserva ou quando um nó se torna ocorrência ativa, devemos percorrer o caminho desse nó até a raiz atualizando o campo $cres$, o que consome tempo esperado~$\O{\lg n}$.


Para concluir essa seção, argumentaremos como ocorre a amortização de custo de \dymGraphDelEdge{}. Notemos que é difícil calcular o número exato de arestas percorridas em uma única execução de \dymGraphReplace{}. No entanto, podemos calcular tal número ao longo de uma sequência de remoções de arestas. Suponhamos que um grafo dinâmico possua $m$ arestas e que iremos remover todas elas uma a uma. No pior dos casos, cada aresta é rebaixada $\lceil \lg n \rceil$ vezes, percorrendo assim todos os níveis da nossa estrutura de dados, e como cada rebaixamento custa $\O{\lg n}$, teremos que o custo total de todas as remoções das $m$ arestas é $\O{m\lg^2 n}$. Logo o custo amortizado de cada remoção é $\O{\lg^2 n}$.






\section{Soluções ótimas para classes específicas de grafos}

O limitante inferior elaborado no Capítulo~\ref{sec:lim} delimita um horizonte de~$\O{\lg n}$ para as soluções do problema de conexidade dinâmica. Vimos no Capítulo~\ref{sec:connDF} que esse horizonte foi alcançado quando restringimos o problema a florestas. Também vimos que a solução ingênua para o problema geral, desenvolvida no início do Capítulo~\ref{sec:connDG}, permite inserção de aresta e consulta de conexidade em tempo ótimo.

Voltamos a destacar que a dificuldade de solucionar o problema de conexidade em grafos dinâmicos é substituir uma aresta que foi removida da MSF que mantemos para realizar a consulta de conexidade.

Em $1992$, Eppstein \textit{et al.} desenvolvem uma maneira de encontrar essa aresta substituta para uma MSF de um grafo planar em~$\O{\lg n}$~\cite{EPPSTEIN-planar}. Consequentemente obtendo assim uma solução ótima para conexidade dinâmica para essa família de grafos.


